{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e71cbd",
   "metadata": {},
   "source": [
    "## Block 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7a1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "#Download des Shakespeare-Texts ins Skript\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "#Nur Ausschnitt des Texts wird verwendet\n",
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484f9ff",
   "metadata": {},
   "source": [
    "## Block 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97885e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "# Array, das alle im Text vorkommenden Buchstaben und Zeichen sortiert enthält\n",
    "characters = sorted(set(text))\n",
    "print(len(characters))\n",
    "# Dictionary, das alle Buchstaben/Zeichen sortiert enthält, die jeweils auf einen Index verweisen\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "# Buchstaben/Zeichen dictionary umgedreht - Index weist auf Zahl\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa6028",
   "metadata": {},
   "source": [
    "## Block 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c7a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SEQ_LENGTH bestimmt die Länge, die ein Satz, der bearbeitet wird, hat\n",
    "SEQ_LENGTH = 40\n",
    "# Step_Size bestimmt den Shift, der zwischen den Sequenzen liegt\n",
    "# Je geringer die STEP_SIZE, desto mehr Trainingssequenzen werden verwendet\n",
    "# Diese überlappen sich dann aber umso mehr\n",
    "STEP_SIZE = 3\n",
    "\n",
    "# In das Array sentences werden alle Sequenzen (Anzahl: (len(text)/SEQ_LENGTH)) gespeichert\n",
    "sentences = []\n",
    "# Das next_char Array enthält jeweils das nächste Zeichen, das nach dem Satz, der\n",
    "# über den selben Index im sentences Array gespeichert ist, im Text kommt\n",
    "next_char = []\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae6b31",
   "metadata": {},
   "source": [
    "# Block 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e60db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x sind unsere Eingabedaten \n",
    "# y enthält unsere Zieldaten\n",
    "# Diese werden dem LSTM zum Trainieren \"gefüttert\"\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41837dcb",
   "metadata": {},
   "source": [
    "# Block 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec02f99a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "651/651 [==============================] - 38s 56ms/step - loss: 2.1867\n",
      "Epoch 2/5\n",
      "651/651 [==============================] - 43s 66ms/step - loss: 1.7401\n",
      "Epoch 3/5\n",
      "651/651 [==============================] - 45s 69ms/step - loss: 1.6018\n",
      "Epoch 4/5\n",
      "651/651 [==============================] - 54s 84ms/step - loss: 1.5286\n",
      "Epoch 5/5\n",
      "651/651 [==============================] - 53s 82ms/step - loss: 1.4812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab3886f5c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unser Modell ist ein Long Short-Term Memory\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bb1fa",
   "metadata": {},
   "source": [
    "## Block 6\n",
    "\n",
    "Aufgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb3cf663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der sample()-Funktion wird ein Array mit Wahrscheinlichkeiten von Zeichen, die als nächstes\n",
    "# im zu generierenden Text verwendet werden können und der sogenannte temperature-Wert übergeben\n",
    "# Je niedriger der Temperaturwert, desto \"realistischer\" wird der Text\n",
    "# Je höher der Temperaturwert, desto kreativer aber auch \"falscher\" kann der Text werden\n",
    "\n",
    "# Funktionen für Aufgabe:\n",
    "# np.log(x)\n",
    "# np.exp(x)\n",
    "# np.sum(x)\n",
    "# np.random.multinomial(1, x, 1)\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    # Die folgenden Anweisungen sorgen dafür, dass verhältnismäßig geringe Wahrscheinlichkeiten\n",
    "    # noch geringer und verhältnismäßig hohe Wahrscheinlichkeiten noch höher werden\n",
    "    # Bei temperature = 1 bleiben die Wahrscheinlichkeiten gleich\n",
    "    # logarithmieren \n",
    "    preds =\n",
    "    # durch temperature teilen\n",
    "    preds =\n",
    "    # exponieren\n",
    "    exp_preds =\n",
    "    # exponierte predictions/summe exponierte predictions\n",
    "    preds =\n",
    "    # \"Zufällige\" Wahl einer der Buchstaben\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bef328",
   "metadata": {},
   "source": [
    "## Block 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d03d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    # Startindex wird so gewählt, dass nicht das Ende des Texts erreicht wird\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    # Die ersten 40 Zeichen werden aus dem Text genommen\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    # Schleife läuft so oft durch, wie die Länge, die übergeben wurde\n",
    "    for i in range(length):\n",
    "        \n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            # x_predictions sind die Eingabedaten auf Basis der aktuellen Sequenz,\n",
    "            # die dem Model gegeben werden   \n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "        # Das Model gibt predictions für alle (39) Zeichen wieder\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        # sample-Funktion \"wählt\" den nächsten Buchstaben aus\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "        # nächster Buchstabe wird angehängt\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e653fbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp: 0.1\n",
      "d queen;\n",
      "and would by combat make her good men the words,\n",
      "that i have the sent and the seek the broke\n",
      "that the seek the sent and the sent a son,\n",
      "and the days the sent and the words with the words,\n",
      "and the sent the sentence to the way the words,\n",
      "and the words with the words in the words,\n",
      "and the sent and the words in the words,\n",
      "and with th\n",
      "temp: 0.5\n",
      "out\n",
      "betwixt the prince and beggar: i have said\n",
      "that the way hath you that is my death couns,\n",
      "and see his heads of my braves and brave\n",
      "and the sadd to the words, where you say,\n",
      "the back to right was the truth would him north,\n",
      "and the shalt that i slard with the words.\n",
      "\n",
      "yerford:\n",
      "is my faith, on shalt his brother of the prince the week.\n",
      "\n",
      "fri\n",
      "temp: 1\n",
      "g!\n",
      "doth set my pugging tooth on edge;\n",
      "for which was swiff, each his shears, or,\n",
      "and tenple skinch touth her! \n",
      "belove:\n",
      "spreeves gage sial of this that i cortels!\n",
      "\n",
      "duke of york:\n",
      "so, o'ergaterapteaty brokes or with\n",
      "that to thee of remeign.\n",
      "\n",
      "rouses:\n",
      "sims should becoury with his reath;\n",
      "for my happy shaltoswurar us then gone,\n",
      "precaiming bay, ee\n",
      "temp: 1.5\n",
      "eshest reputation to\n",
      "a savour that may shalp?c propsessitabt3,\n",
      "love to our bkry til fly for my seve w liak,\n",
      "\n",
      "opmoornon-blesting: la! richard!-elke udtlcueabegs whom. no,\n",
      "\n",
      "wricsa::'s.\n",
      "friar: faith adredieve mosen with woums.\n",
      "m us which nadel wouldre: the suicencity?\n",
      "an if a uospeststingman!\n",
      "p-score\n",
      "if inlonake: clifbidpsike';bmorso, he prr\n"
     ]
    }
   ],
   "source": [
    "print('temp: 0.5')\n",
    "print(generate_text(300, 0.5))\n",
    "print('temp: 1')\n",
    "print(generate_text(300, 1))\n",
    "print('temp: 1.5')\n",
    "print(generate_text(300, 1.5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
